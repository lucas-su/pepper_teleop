<!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <title>Introduction</title>
        <style>
/* From extension vscode.github */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

.vscode-dark img[src$=\#gh-light-mode-only],
.vscode-light img[src$=\#gh-dark-mode-only] {
	display: none;
}

</style>
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<link href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/highlight.css">
<style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
                font-size: 14px;
                line-height: 1.6;
            }
        </style>
        <style>
.task-list-item {
    list-style-type: none;
}

.task-list-item-checkbox {
    margin-left: -20px;
    vertical-align: middle;
    pointer-events: none;
}
</style>
        
    </head>
    <body class="vscode-body vscode-light">
        <h1 id="introduction">Introduction</h1>
<p>This document contains the steps necessary to install <code>ros</code>, <code>openpose</code>, the <code>azure kinect driver</code>, <code>ros openpose</code> and the <code>naoqi bridge</code>. This will enable you to do pose estimation on human bodies and copy the estimated pose to the robot.</p>
<p>The general goal is to copy the pose of a human body to a robot. The pose of the human body is estimated through a computer vision model. Through this estimate, the joint angles of the joints on the human body can be derived, which can be translated to joint angles in the robot's joint space. We can then send these joint angles to robot to make the robot mimick us.</p>
<p>There are several ways to do pose estimation, and this document provides instructions for different configurations. It is therefore not necessary to go through <strong>every</strong> step, and only the steps which are required for the configuration you want need to be followed. <code>Openpose</code> enables you to use RGB cameras (eg. webcams) to get started without an RGBD camera. However openpose is limited to 2D pose estimation unless you connect 2 cameras. Alternatively, an RGBD camera (such as the <code>Azure Kinect</code>) can do 3D pose estimation which is required to properly translate poses between the human and the robot.</p>
<p>Ros is used as a middleware in any of the configurations, and the <code>Naoqi bridge</code> is necessary to interface with the Pepper robot from ros.</p>
<p>This software can only be used with linux and was tested on ubuntu 20 (however unless your hardware is very new, ubuntu 18 is probably easier to configure). Many install steps are dependent on the version you are using.</p>
<p>Let's get started! I like to install these nice-to-haves but they are not necessary</p>
<pre><code>sudo apt install terminator aptitude
sudo snap install vscode
</code></pre>
<h1 id="general-requirements">General requirements</h1>
<p>These packages are necessary for multiple steps along the way and should be available on any linux distribution:</p>
<pre><code>sudo apt install curl git libblas-dev liblapack-dev libatlas-base-dev python python3-pip
</code></pre>
<h1 id="ros">Ros</h1>
<p>Installing Robotic Operating System</p>
<pre><code>sudo sh -c 'echo &quot;deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list'

curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add -

sudo apt update
</code></pre>
<p>Different linux versions come with different ros versions, replace <em>noetic</em> with <em>melodic</em> if you are using ubuntu 18. See <a href="http://wiki.ros.org/Distributions">http://wiki.ros.org/Distributions</a> for earlier versions.</p>
<pre><code>sudo apt install ros-noetic-desktop-full
</code></pre>
<p>Source environment correctly:</p>
<pre><code>echo &quot;source /opt/ros/noetic/setup.bash&quot; &gt;&gt; ~/.bashrc
source ~/.bashrc
</code></pre>
<pre><code>python -m pip install PyYAML rospkg
</code></pre>
<h1 id="azure-kinect-ros-driver">Azure kinect ros driver</h1>
<p>This is necessary to get the Azure kinect RGBD camera working in ros. If you want to use other cameras with Openpose, you need other drivers.</p>
<ul>
<li><a href="https://github.com/IntelRealSense/realsense-ros">Realsense-ros</a>: For Intel RealSense Camera</li>
<li><a href="https://github.com/code-iai/iai_kinect2">iai_kinect2</a>: For Microsoft Kinect v2 Camera</li>
<li><a href="https://github.com/stereolabs/zed-ros-wrapper">zed-ros-wrapper</a>: For Stereolabs ZED2 Camera</li>
</ul>
<p>Again, change 20.04 to 18.04 if on ubuntu 18.</p>
<pre><code>curl -sSL https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc

sudo apt-add-repository https://packages.microsoft.com/ubuntu/20.04/prod
</code></pre>
<p>Somehow this package assumes an i386 architecture, modify <code>/etc/apt/sources.list</code>. At the bottom of the file, change this:</p>
<pre><code>deb https://packages.microsoft.com/ubuntu/20.04/prod focal main
# deb-src https://packages.microsoft.com/ubuntu/20.04/prod focal main
</code></pre>
<p>to:</p>
<pre><code>deb [arch=amd64] https://packages.microsoft.com/ubuntu/20.04/prod focal main
# deb-src [arch=amd64] https://packages.microsoft.com/ubuntu/20.04/prod focal main
</code></pre>
<hr>
<p>If you are on ubuntu 18 you can install k4a, version 1.3 works out of the box. However, if you have an RTX 30XX graphics card you need version 1.4. You then also need to edit <code>$HOME/pepper_teleop/catkin_ws/src/Azure_Kinect_ROS_Driver/CMakeLists.txt</code> and <a href="https://github.com/microsoft/Azure_Kinect_ROS_Driver/blob/melodic/docs/building.md#alternate-sdk-installation">manually copy the sdk files</a> to make sure it finds the right version</p>
<pre><code>sudo apt-get update
sudo apt install k4a-tools=1.3.*
sudo apt install libk4a1.3
sudo apt install libk4a1.3-dev
</code></pre>
<p>If you are on ubuntu 20, these packages are not available and it is easiest to just download them. Download the 1.4 versions <code>libk4a</code> and the 1.1 versions of <code>libk4abt</code> if you have an RTX 30XX card.</p>
<pre><code>wget https://packages.microsoft.com/ubuntu/18.04/prod/pool/main/libk/libk4a1.3/libk4a1.3_1.3.0_amd64.deb
wget https://packages.microsoft.com/ubuntu/18.04/prod/pool/main/libk/libk4a1.3-dev/libk4a1.3-dev_1.3.0_amd64.deb
wget https://packages.microsoft.com/ubuntu/18.04/prod/pool/main/libk/libk4abt1.0/libk4abt1.0_1.0.0_amd64.deb
wget https://packages.microsoft.com/ubuntu/18.04/prod/pool/main/libk/libk4abt1.0-dev/libk4abt1.0-dev_1.0.0_amd64.deb
wget https://packages.microsoft.com/ubuntu/18.04/prod/pool/main/k/k4a-tools/k4a-tools_1.3.0_amd64.deb

</code></pre>
<p>Install all above packages:</p>
<pre><code>sudo dpkg -i libk4a1.3_1.3.0_amd64.deb
sudo dpkg -i libk4a1.3-dev_1.3.0_amd64.deb
sudo dpkg -i libk4abt1.0_1.0.0_amd64.deb
sudo dpkg -i libk4abt1.0-dev_1.0.0_amd64.deb
sudo dpkg -i libk4a1.3_1.3.0_amd64.deb
sudo dpkg -i k4a-tools_1.3.0_amd64.deb
</code></pre>
<p>The driver also requires <code>cuda</code>. There are installation instructions for <code>cuda</code> in the <code>openpose</code> section. If you are not going to also use <code>openpose</code>, you can install any version you like.</p>
<hr>
<h2 id="azure-kinect-driver-itself">Azure kinect driver itself</h2>
<pre><code>sudo apt install ninja-build

mkdir $HOME/pepper_teleop/catkin_ws/src
cd $HOME/pepper_teleop/catkin_ws/src
git clone https://github.com/microsoft/Azure_Kinect_ROS_Driver.git

mkdir build &amp;&amp; cd build
cmake .. -GNinja
ninja
sudo ninja install
</code></pre>
<p>From here, the Azure Kinect driver can perform 3D body tracking. You can lauch the body tracking with</p>
<pre><code>roslaunch azure_kinect_ros_driver driver_with_bodytracking.launch 
</code></pre>
<p>The points tracked in the Azure kinect tracking are the following:
<img src="https://learn.microsoft.com/en-us/azure/kinect-dk/media/concepts/joint-hierarchy.png" alt=""></p>
<p>The indices in the /body_tracking_data topic are as follows:</p>
<ol start="0">
<li>PELVIS</li>
<li>SPINE_NAVEL</li>
<li>SPINE_CHEST</li>
<li>NECK</li>
<li>CLAVICLE_LEFT</li>
<li>SHOULDER_LEFT</li>
<li>ELBOW_LEFT</li>
<li>WRIST_LEFT</li>
<li>HAND_LEFT</li>
<li>HANDTIP_LEFT</li>
<li>THUMB_LEFT</li>
<li>CLAVICLE_RIGHT</li>
<li>SHOULDER_RIGHT</li>
<li>ELBOW_RIGHT</li>
<li>WRIST_RIGHT</li>
<li>HAND_RIGHT</li>
<li>HANDTIP_RIGHT</li>
<li>THUMB_RIGHT</li>
<li>HIP_LEFT</li>
<li>KNEE_LEFT</li>
<li>ANKLE_LEFT</li>
<li>FOOT_LEFT</li>
<li>HIP_RIGHT</li>
<li>KNEE_RIGHT</li>
<li>ANKLE_RIGHT</li>
<li>FOOT_RIGHT</li>
<li>HEAD</li>
<li>NOSE</li>
<li>EYE_LEFT</li>
<li>EAR_LEFT</li>
<li>EYE_RIGHT</li>
<li>EAR_RIGHT</li>
</ol>
<hr>
<h1 id="openpose">Openpose</h1>
<p>Openpose can be used to estimate the pose of a human. It support multiple camera types, both RGB and RGBD. It can be build with cuda support to increase performance, but can also run on CPU if you do not have a graphics card.</p>
<h2 id="cuda">Cuda</h2>
<p>Openpose requires cuda. Some cuda versions might not work well, and you may need specific cuda versions to work with your specific graphics card. Cuda 11.7 supports almost all modern graphics cards and is tested with openpose so this version is recommended.</p>
<p>Change <code>ubuntu2004</code> in the following with <code>ubuntu1804</code> if you are running ubuntu 18.</p>
<pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin

sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600

wget https://developer.download.nvidia.com/compute/cuda/11.7.0/local_installers/cuda-repo-ubuntu2004-11-7-local_11.7.0-515.43.04-1_amd64.deb

sudo dpkg -i cuda-repo-ubuntu2004-11-7-local_11.7.0-515.43.04-1_amd64.deb

sudo cp /var/cuda-repo-ubuntu2004-11-7-local/cuda-*-keyring.gpg /usr/share/keyrings/

sudo apt-get update

sudo apt-get -y install cuda
</code></pre>
<h2 id="cudnn">cuDnn</h2>
<p>Like cuda, the specific version of cuDnn is important for the software to run correctly. Version 8.5 is tested and is hence recommended.</p>
<p>Change <code>ubuntu2004</code> in the following with <code>ubuntu1804</code> if you are running ubuntu 18. Change the cuda version if you are running an other cuda version than 11.7.</p>
<pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin 

sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub
sudo add-apt-repository &quot;deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /&quot;
sudo apt-get update

sudo apt-get install libcudnn8=8.5.0.*-1+cuda11.7
sudo apt-get install libcudnn8-dev=8.5.0.*-1+cuda11.7
</code></pre>
<h2 id="openpose-itself">Openpose itself</h2>
<p>Now we get to build openpose itself.</p>
<pre><code>sudo apt install libgflags-dev libgoogle-glog-dev

git clone https://github.com/CMU-Perceptual-Computing-Lab/openpose.git

cd openpose

git checkout tags/v1.7.0

git submodule update --init --recursive --remote
</code></pre>
<p>If you do not have a graphics card, you can use openpose by building it for cpu only but the performance will be poor. You can do this by setting the <code>GPU_MODE</code> in the openpose <code>CMakeLists.txt</code> to <code>CPU_ONLY</code>.</p>
<pre><code>mkdir build/

cd build/

cmake ..

make -j`nproc`

sudo make install
</code></pre>
<p>If you get 'unsupported compute type' errors when building caffe as part of openpose, edit <code>/openpose/3rdparty/caffe/cmake/Cuda.cmake</code> and <code>$HOME/pepper_teleop/openpose/cmake/Cuda.cmake</code> to reflect the correct graphics card for your device (eg. <code>set(Caffe_known_gpu_archs &quot;${AMPERE}&quot;)</code>)</p>
<h1 id="ros-openpose">Ros openpose</h1>
<p>An openpose to ros bridge, to use openpose recognized poses in ros.
<em>from <a href="https://github.com/ravijo/ros_openpose">https://github.com/ravijo/ros_openpose</a></em></p>
<pre><code>cd $HOME/pepper_teleop/catkin_ws/src
git clone https://github.com/ravijo/ros_openpose.git
cd $HOME/pepper_teleop/catkin_ws
catkin_make
</code></pre>
<hr>
<p>There's a small bug in the code, which can sometimes cause the program to crash, to fix this change line 158 in <code>$HOME/pepper_teleop/catkin_ws/src/ros_openpose/scripts/visualizer.py</code> from</p>
<pre><code>strip_id = idx / self.count_keypoints_one_finger
</code></pre>
<p>to</p>
<pre><code>strip_id = int(idx / self.count_keypoints_one_finger)
</code></pre>
<hr>
<p>We can test ros_openpose with</p>
<pre><code>roslaunch ros_openpose run.launch camera:=azurekinect
</code></pre>
<p>If you want to render the hands as well add <code>--hand</code> to <code>openpose_args</code> and change <code>skeleton_hands</code> to <code>true</code> in <code>$HOME/pepper_teleop/catkin_ws/src/ros_openpose/launch/run.launch</code></p>
<p>If you get out of memory errors, you can reduce the resolution of the openpose network with <code>--net-resolution -1x256</code> or smaller in <code>openpose_args</code> in <code>$HOME/pepper_teleop/catkin_ws/src/ros_openpose/launch/run.launch</code></p>
<h2 id="openpose-body-points">openpose body points</h2>
<p><img src="https://cmu-perceptual-computing-lab.github.io/openpose/web/html/.github/media/keypoints_pose_25.png" alt="body points"></p>
<h1 id="naoqi-bridge">Naoqi bridge</h1>
<p>A bridge which is required to connect to the pepper robot from ros</p>
<p>Install the naoqi bridge with</p>
<pre><code>sudo apt-get install ros-noetic-naoqi-bridge-msgs  ros-noetic-naoqi-libqicore
ros-noetic-naoqi-libqi 

cd $HOME/pepper_teleop/catkin_ws/src
git clone https://github.com/ros-naoqi/naoqi_driver.git
cd $HOME/pepper_teleop/catkin_ws/
catkin_make
</code></pre>
<p>Launch with</p>
<pre><code>roslaunch naoqi_driver naoqi_driver.launch nao_ip:=192.168.1.61 roscore_ip:=127.0.0.1 network_interface:=eth0
</code></pre>
<p>The <code>roscore_ip</code> is probably correct, but the network interface might not be. This should be updated with whatever <code>ifconfig</code> says your network interface is called. This can be eth0/vpn1/wlp4s0/... The <code>nao_ip</code> should match the pepper's ip, which you can find out by pressing the button under the tablet once.</p>
<h2 id="your-own-code">Your own code!</h2>
<p>Use the following to create a new package with the dependencies you will need.</p>
<pre><code>catkin_create_pkg control_pepper geometry_msgs std_msgs rospy roscpp naoqi_bridge_msgs joy
</code></pre>
<p>You can publish <a href="http://docs.ros.org/en/jade/api/naoqi_bridge_msgs/html/msg/JointAnglesWithSpeed.html"><code>naoqi_bridge_msgs/JointAnglesWithSpeed</code></a> messages to the topic <code>/joint_angles</code> to command the joints. The <code>JointAnglesWithSpeed</code> consists of a <code>header</code>, <code>joint_names</code>, <code>joint_angles</code>, <code>speed</code> and <code>relative</code></p>
<p>The <code>joint_names</code> are documented on <a href="http://doc.aldebaran.com/2-5/family/pepper_technical/joints_pep.html">http://doc.aldebaran.com/2-5/family/pepper_technical/joints_pep.html</a> and can be the following:</p>
<ul>
<li>HeadYaw</li>
<li>HeadPitch</li>
<li>LShoulderPitch</li>
<li>LShoulderRoll</li>
<li>LElbowYaw</li>
<li>LElbowRoll</li>
<li>LWristYaw</li>
<li>LHand</li>
<li>HipRoll</li>
<li>HipPitch</li>
<li>KneePitch</li>
<li>RShoulderPitch</li>
<li>RShoulderRoll</li>
<li>RElbowYaw</li>
<li>RElbowRoll</li>
<li>RWristYaw</li>
<li>RHand</li>
<li>WheelFL</li>
<li>WheelFR</li>
<li>WheelB</li>
</ul>
<p>The <code>joint_angles</code> are values in <strong>radians</strong>. Naturally, the number of <code>joint_angles</code> should be equal to the number of <code>joint_names</code>, but they do not need to all be present.</p>
<p>The <code>speed</code> is between 0 and 1, where 1 is the maximum speed</p>
<p><code>relative</code> sets relative or absolute movement.</p>

        <script async src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script>
        
    </body>
    </html>